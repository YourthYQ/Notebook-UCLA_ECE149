## Vision

> In fields like computer vision and artificial intelligence, vision refers to **the process by which machines or systems interpret and understand visual data from the world**, much like human vision. It involves enabling computers to “see,” analyze, and make decisions based on visual inputs (like images or videos).

### Example 1: Autopilot (Self-driving Car):

* Tesla’s Autopilot system uses computer vision for lane-keeping, adaptive cruise control, and obstacle detection. The car processes visual data to navigate roads and highways autonomously.

### Example 2: Robotics and Industrial Automation

*  Amazon’s warehouse robots use computer vision to pick, pack, and sort items. They identify products on shelves, locate them, and move them to different areas in the warehouse.

### Example3: Facial Recognition

* Apple’s Face ID unlocks iPhones by scanning the user’s face and using vision algorithms to recognize and authenticate them. It’s also used in security systems and social media platforms like Facebook for tagging people in photos.

### Example 4: Medical Imaging

---

## Three Rs

### 1. Representation

>  **How visual data (images or videos) are stored and manipulated within a computer memory**. It deals with the mathematical and computational ways of encoding and processing images.

* **Key Concepts**: Image filtering, noise reduction, basis representation, compressed sensing, etc.

* **Example**: When you take a grayscale image, it can be represented as a 2D matrix where each element corresponds to the brightness (pixel value) of a certain point in the image. For instance, a 640x480 grayscale image would have 307,200 pixel values. In representation, you might use techniques like Fourier transforms or wavelets to represent the image in a different domain (frequency domain) for tasks like compression or noise removal.

### 2. Reconstruction

>  Involves **converting 2D images into 3D representations of the world**. It addresses how to infer depth and shape from flat, two-dimensional images.

* **Key Concepts**: Camera models, 2D transformations, homography, structure from motion, panoramic stitching (全景拼接), stereo vision, surface reconstruction, etc.

* **Example**: Imagine a series of 2D images taken from different angles around an object. Using reconstruction techniques such as **Structure from Motion (SfM)**, you can create a 3D model of that object, which is essential in applications like virtual reality (VR), robotics, and 3D modeling.

### 3. Recognition

> **Process of identifying objects, people, or scenes in images or videos and extracting semantic meaning** (e.g., labeling objects or understanding relationships between objects in a scene).

* **Key Concepts**: Object detection, semantic segmentation, instance segmentation, neural networks, convolutional neural networks (ConvNets), etc.

* **Example**: Facial recognition systems use recognition algorithms to identify individuals from images or video feeds. For example, **Eigenfaces** is a technique used to recognize faces by reducing high-dimensional facial data into a set of principal components. Similarly, **ConvNets** are used to detect and classify objects in images (e.g., identifying a dog or a cat in a photo).

### 4. (Optional) Rendering

> **Process of generating an image or visual scene from a mathematical or abstract representation**, often using 3D models or 2D layouts. It is the **opposite of what happens in computer vision**: while vision focuses on understanding images, rendering focuses on creating them.



> Q: How many different 8-bit grayscale images of size 640x480 can you count?

> * `640x480` means the image has 640 x 480 = **307,200 total pixels**
>
> * `8-bit grayscale` means each pixel can represent **256 different shades of gray**, ranging from black (0) to white (255)

>  A: `256^(307,200)`